- F T T T F F T F T T
  logseq.order-list-type:: number
- (1) CBOW KNN KMeans VAE
  logseq.order-list-type:: number
- (2) 较底层：偏词本意在词义空间上
	- self-attention:  使用attention上对文章上下文的语义进行凝练
- (3) 这个可以类比RNN的循环神经网络，在较前的输入由于时间序列的影响导致梯度消失，导致无法记忆较前的输入层，导致记忆衰退。这对应汉字拼读在时间序列中，目前大多数人读得多导致语言模型基于记忆到目前的拼读。同时由于训练集中qi的人数增加，导致训练时对qi过拟合。
- (5) 迁移学习，比如大语言模型调参，例如bert，bert通过在通用语料上的进行训练，然后在进行翻译任务中通过将特定的双语语料进行输入，得到翻译任务的知识。又或者在visual-transformer中通过使用region-aware network以及特征提取器将特征翻译成sequence再利用预训练后的transformer调参，则能做到图像caption生成。
- 4.
- 数据处理： 先对数据集进行划分，由于数据量庞大，可以划分成97:2:1的训练集，验证集以及测试集，预处理时对我们需要进行超采样的图片进行不同程度的降采样操作，对于每一个样例按照(image_downsize, image_downsize_2, ..., image_down_size_n, image_real) 的格式。
- 模型架构： 由于整个网络是一个自监督的网络，且每次超采样过程，我认为都可以认为是一个编解码的过程，所以我们可以尝试使用且我们是尝试从低采样模型生成到高采样的模型，所以我们可以使用一个Conditional-GAN类似的架构来进行。更细节的说，我们可以将每张图片都输入一个UNet类似的网络架构，再decoder阶段则可以将所有的超采样分辨率的图片进行收集与不同分辨率的原图片进行比较。对于GAN的Loss的产生，在判别器中我们可以采用特征提取器的方式，然后运行GAN的Loss
- 损失函数：$Min_GMAX_D log(D(ir)) + log(1-D(G(i))$
- 训练：使用ADAM算法，调整Batchsize，按照需求配置scheduler以及精度下降，先按照上述过程训练判别器，训练完成后则优化生成器，最终模型结束。
- 预测： 将低采样图片输入生成器，得到所求图形。
- (2) ChatGPT的主要思路 RLHF
- 数据收集：通过用户输入以及互联网上爬虫所收集的语料，并通过预训练的BERT分类模型，将他们都进行分类收集
- 模型架构：如果使用强化学习进行思考，则我们可以将每一次GPT所生成句子作为状态，则GPT的每一次下次的生成状态则可以称为一次动作，则GPT每一次通过Transformer的自编解码机制预测的下一个词的结果都可以算作时刻t，整个过程到文章生成结束为止，故为马尔科夫有限决策过程。而人工打出的分数则是可以算作一次奖赏，可以作用于文章生成的各个阶段t上采取权重，并作用在最后一个词的生成当中。
- 损失函数：$L(x;G) = \sum_{i=1}^TR(i)log(x_i; x_0,x_1,x_2...x_{t-1})$ 其中 $R(i) = R_i + R_i+1 * \gamma+ ... + R_t * \gamma ^{t-1}$ R_i由人工指定多阶段判定
- 训练：由于GPT参数庞大，则可以在冻结GPT参数中，使用PETA的方法通过该种手段训练中间层，然后使用ADAM优化器进行优化。